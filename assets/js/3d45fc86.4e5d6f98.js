"use strict";(globalThis.webpackChunkace_wiki=globalThis.webpackChunkace_wiki||[]).push([[6052],{50:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"tutorials/containers/advanced-builds","title":"Advanced Build Topics","description":"This tutorial covers advanced container building techniques including multi-stage builds, GPU-enabled containers, MPI support, and optimization strategies for HPC workloads.","source":"@site/docs/tutorials/containers/advanced-builds.md","sourceDirName":"tutorials/containers","slug":"/tutorials/containers/advanced-builds","permalink":"/ace-ug-hpc-wiki/docs/tutorials/containers/advanced-builds","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tutorials/containers/advanced-builds.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"advanced-builds","title":"Advanced Build Topics","sidebar_label":"Advanced Build Topics","sidebar_position":3},"sidebar":"wikiSidebar","previous":{"title":"Containers on HPC","permalink":"/ace-ug-hpc-wiki/docs/tutorials/containers/containers-hpc"}}');var r=i(4848),a=i(8453);const s={id:"advanced-builds",title:"Advanced Build Topics",sidebar_label:"Advanced Build Topics",sidebar_position:3},l="Advanced Build Topics",o={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Multi-Stage Builds",id:"multi-stage-builds",level:2},{value:"The Problem: Large Images",id:"the-problem-large-images",level:3},{value:"The Solution: Multi-Stage Build",id:"the-solution-multi-stage-build",level:3},{value:"Exercise 1: Multi-Stage Build for C++ Application",id:"exercise-1-multi-stage-build-for-c-application",level:3},{value:"GPU-Enabled Containers",id:"gpu-enabled-containers",level:2},{value:"NVIDIA CUDA Containers",id:"nvidia-cuda-containers",level:3},{value:"CUDA Image Variants",id:"cuda-image-variants",level:3},{value:"Exercise 2: PyTorch GPU Container",id:"exercise-2-pytorch-gpu-container",level:3},{value:"TensorFlow GPU Container",id:"tensorflow-gpu-container",level:3},{value:"MPI Containers for Parallel Computing",id:"mpi-containers-for-parallel-computing",level:2},{value:"MPI Container Strategy",id:"mpi-container-strategy",level:3},{value:"Exercise 3: MPI Container",id:"exercise-3-mpi-container",level:3},{value:"Running MPI Containers on ACE HPC",id:"running-mpi-containers-on-ace-hpc",level:3},{value:"Optimization Techniques",id:"optimization-techniques",level:2},{value:"1. Minimize Layers",id:"1-minimize-layers",level:3},{value:"2. Order by Change Frequency",id:"2-order-by-change-frequency",level:3},{value:"3. Use .dockerignore",id:"3-use-dockerignore",level:3},{value:"4. Pin Versions for Reproducibility",id:"4-pin-versions-for-reproducibility",level:3},{value:"5. Use Specific Base Image Digests",id:"5-use-specific-base-image-digests",level:3},{value:"Security Best Practices",id:"security-best-practices",level:2},{value:"1. Run as Non-Root User",id:"1-run-as-non-root-user",level:3},{value:"2. Never Include Secrets",id:"2-never-include-secrets",level:3},{value:"3. Use Official Base Images",id:"3-use-official-base-images",level:3},{value:"4. Verify Downloads",id:"4-verify-downloads",level:3},{value:"5. Minimize Attack Surface",id:"5-minimize-attack-surface",level:3},{value:"Exercise 4: Optimized ML Container",id:"exercise-4-optimized-ml-container",level:2},{value:"Container Size Comparison",id:"container-size-comparison",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"advanced-build-topics",children:"Advanced Build Topics"})}),"\n",(0,r.jsx)(e.p,{children:"This tutorial covers advanced container building techniques including multi-stage builds, GPU-enabled containers, MPI support, and optimization strategies for HPC workloads."}),"\n",(0,r.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(e.p,{children:"After completing this tutorial, you will be able to:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Use multi-stage builds to create smaller, more efficient images"}),"\n",(0,r.jsx)(e.li,{children:"Build GPU-enabled containers for CUDA and machine learning"}),"\n",(0,r.jsx)(e.li,{children:"Create MPI-enabled containers for parallel computing"}),"\n",(0,r.jsx)(e.li,{children:"Optimize containers for size and performance"}),"\n",(0,r.jsx)(e.li,{children:"Implement security best practices"}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"multi-stage-builds",children:"Multi-Stage Builds"}),"\n",(0,r.jsxs)(e.p,{children:["Multi-stage builds allow you to use multiple ",(0,r.jsx)(e.code,{children:"FROM"})," statements in a single Dockerfile. This is powerful for separating build-time dependencies from runtime dependencies, resulting in much smaller final images."]}),"\n",(0,r.jsx)(e.h3,{id:"the-problem-large-images",children:"The Problem: Large Images"}),"\n",(0,r.jsx)(e.p,{children:"A typical build includes compilers, development headers, and build tools:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'# Single-stage build (large image)\nFROM python:3.11\n\n# Install build tools\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    gfortran \\\n    libopenblas-dev\n\n# Install Python packages (some require compilation)\nRUN pip install numpy scipy pandas scikit-learn\n\n# Your application\nCOPY app.py /app/\nCMD ["python", "/app/app.py"]\n\n# Result: ~2GB image with unnecessary build tools\n'})}),"\n",(0,r.jsx)(e.h3,{id:"the-solution-multi-stage-build",children:"The Solution: Multi-Stage Build"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'# Stage 1: Builder\nFROM python:3.11 AS builder\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    gfortran \\\n    libopenblas-dev\n\n# Create virtual environment and install packages\nRUN python -m venv /opt/venv\nENV PATH="/opt/venv/bin:$PATH"\nRUN pip install --no-cache-dir numpy scipy pandas scikit-learn\n\n# Stage 2: Runtime (final image)\nFROM python:3.11-slim\n\n# Install only runtime dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    libopenblas0 \\\n    libgomp1 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Copy the virtual environment from builder\nCOPY --from=builder /opt/venv /opt/venv\nENV PATH="/opt/venv/bin:$PATH"\n\n# Your application\nWORKDIR /app\nCOPY app.py .\nCMD ["python", "app.py"]\n\n# Result: ~500MB image with only what\'s needed\n'})}),"\n",(0,r.jsx)(e.h3,{id:"exercise-1-multi-stage-build-for-c-application",children:"Exercise 1: Multi-Stage Build for C++ Application"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"mkdir -p ~/multistage-demo\ncd ~/multistage-demo\n"})}),"\n",(0,r.jsx)(e.p,{children:"Create a simple C++ program:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > hello.cpp << \'EOF\'\n#include <iostream>\n#include <string>\n\nint main(int argc, char* argv[]) {\n    std::string name = (argc > 1) ? argv[1] : "World";\n    std::cout << "Hello, " << name << "!" << std::endl;\n    std::cout << "This binary was compiled inside a container." << std::endl;\n    return 0;\n}\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Create a multi-stage Dockerfile:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"cat > Dockerfile << 'EOF'\n# Stage 1: Build\nFROM gcc:12 AS builder\n\nWORKDIR /build\nCOPY hello.cpp .\nRUN g++ -static -o hello hello.cpp\n\n# Stage 2: Runtime\nFROM debian:bookworm-slim\n\nWORKDIR /app\nCOPY --from=builder /build/hello .\n\nENTRYPOINT [\"./hello\"]\nEOF\n"})}),"\n",(0,r.jsx)(e.p,{children:"Build and compare sizes:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Build multi-stage version\ndocker build -t hello-multi:1.0 .\n\n# Build single-stage for comparison\ncat > Dockerfile.single << 'EOF'\nFROM gcc:12\nWORKDIR /app\nCOPY hello.cpp .\nRUN g++ -static -o hello hello.cpp\nENTRYPOINT [\"./hello\"]\nEOF\n\ndocker build -f Dockerfile.single -t hello-single:1.0 .\n\n# Compare sizes\ndocker images | grep hello\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Expected output:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"hello-single   1.0    ...    1.4GB\nhello-multi    1.0    ...    80MB\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"gpu-enabled-containers",children:"GPU-Enabled Containers"}),"\n",(0,r.jsx)(e.h3,{id:"nvidia-cuda-containers",children:"NVIDIA CUDA Containers"}),"\n",(0,r.jsx)(e.p,{children:"For GPU computing, start with NVIDIA's official CUDA images:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'# PyTorch with CUDA\nFROM nvidia/cuda:12.2.0-cudnn8-runtime-ubuntu22.04\n\n# Install Python\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3 \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install PyTorch with CUDA support\nRUN pip3 install --no-cache-dir \\\n    torch \\\n    torchvision \\\n    torchaudio \\\n    --index-url https://download.pytorch.org/whl/cu121\n\nWORKDIR /app\nCMD ["python3"]\n'})}),"\n",(0,r.jsx)(e.h3,{id:"cuda-image-variants",children:"CUDA Image Variants"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Image Tag"}),(0,r.jsx)(e.th,{children:"Contents"}),(0,r.jsx)(e.th,{children:"Size"}),(0,r.jsx)(e.th,{children:"Use Case"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"nvidia/cuda:12.2.0-base-ubuntu22.04"})}),(0,r.jsx)(e.td,{children:"CUDA runtime only"}),(0,r.jsx)(e.td,{children:"~200MB"}),(0,r.jsx)(e.td,{children:"Running pre-compiled CUDA apps"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"nvidia/cuda:12.2.0-runtime-ubuntu22.04"})}),(0,r.jsx)(e.td,{children:"Runtime + cuBLAS, cuFFT"}),(0,r.jsx)(e.td,{children:"~1.5GB"}),(0,r.jsx)(e.td,{children:"Most ML inference"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"nvidia/cuda:12.2.0-devel-ubuntu22.04"})}),(0,r.jsx)(e.td,{children:"Runtime + compilers"}),(0,r.jsx)(e.td,{children:"~4GB"}),(0,r.jsx)(e.td,{children:"Compiling CUDA code"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.code,{children:"nvidia/cuda:12.2.0-cudnn8-runtime-ubuntu22.04"})}),(0,r.jsx)(e.td,{children:"Runtime + cuDNN"}),(0,r.jsx)(e.td,{children:"~2GB"}),(0,r.jsx)(e.td,{children:"Deep learning"})]})]})]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-2-pytorch-gpu-container",children:"Exercise 2: PyTorch GPU Container"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"mkdir -p ~/pytorch-gpu\ncd ~/pytorch-gpu\n"})}),"\n",(0,r.jsx)(e.p,{children:"Create a GPU test script:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > test_gpu.py << \'EOF\'\n#!/usr/bin/env python3\n"""Test GPU availability and run a simple computation."""\n\nimport torch\nimport time\n\ndef main():\n    print("=" * 60)\n    print("PyTorch GPU Test")\n    print("=" * 60)\n\n    print(f"\\nPyTorch version: {torch.__version__}")\n    print(f"CUDA available: {torch.cuda.is_available()}")\n\n    if torch.cuda.is_available():\n        print(f"CUDA version: {torch.version.cuda}")\n        print(f"cuDNN version: {torch.backends.cudnn.version()}")\n        print(f"Number of GPUs: {torch.cuda.device_count()}")\n\n        for i in range(torch.cuda.device_count()):\n            props = torch.cuda.get_device_properties(i)\n            print(f"\\nGPU {i}: {props.name}")\n            print(f"  Memory: {props.total_memory / 1024**3:.1f} GB")\n            print(f"  Compute capability: {props.major}.{props.minor}")\n\n        # Benchmark: Matrix multiplication\n        print("\\n" + "=" * 60)\n        print("Running GPU benchmark...")\n        size = 10000\n\n        # Create random matrices on GPU\n        a = torch.randn(size, size, device=\'cuda\')\n        b = torch.randn(size, size, device=\'cuda\')\n\n        # Warm-up\n        torch.matmul(a, b)\n        torch.cuda.synchronize()\n\n        # Benchmark\n        start = time.time()\n        for _ in range(10):\n            c = torch.matmul(a, b)\n        torch.cuda.synchronize()\n        elapsed = time.time() - start\n\n        print(f"10x Matrix multiplication ({size}x{size}): {elapsed:.3f} seconds")\n        print(f"Throughput: {10 * 2 * size**3 / elapsed / 1e12:.2f} TFLOPS")\n    else:\n        print("\\nNo GPU available. Running on CPU.")\n        print("To enable GPU, run with: apptainer exec --nv container.sif ...")\n\n    print("=" * 60)\n\nif __name__ == "__main__":\n    main()\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Create the Dockerfile:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > Dockerfile << \'EOF\'\nFROM nvidia/cuda:12.2.0-cudnn8-runtime-ubuntu22.04\n\nLABEL maintainer="your.email@example.com"\nLABEL description="PyTorch with CUDA support"\n\n# Prevent interactive prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install Python and dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3 \\\n    python3-pip \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install PyTorch with CUDA\nRUN pip3 install --no-cache-dir \\\n    torch \\\n    torchvision \\\n    torchaudio \\\n    --index-url https://download.pytorch.org/whl/cu121\n\nWORKDIR /app\nCOPY test_gpu.py .\n\nCMD ["python3", "test_gpu.py"]\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Build and push:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"docker build -t pytorch-gpu:1.0 .\ndocker tag pytorch-gpu:1.0 yourusername/pytorch-gpu:1.0\ndocker push yourusername/pytorch-gpu:1.0\n"})}),"\n",(0,r.jsx)(e.p,{children:"On ACE HPC:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"module load apptainer\napptainer exec --nv docker://yourusername/pytorch-gpu:1.0 python3 /app/test_gpu.py\n"})}),"\n",(0,r.jsx)(e.h3,{id:"tensorflow-gpu-container",children:"TensorFlow GPU Container"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'# TensorFlow with GPU\nFROM tensorflow/tensorflow:2.14.0-gpu\n\nLABEL description="TensorFlow with GPU support"\n\n# Install additional packages\nRUN pip install --no-cache-dir \\\n    pandas \\\n    matplotlib \\\n    scikit-learn\n\nWORKDIR /app\nCOPY train.py .\n\nCMD ["python", "train.py"]\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"mpi-containers-for-parallel-computing",children:"MPI Containers for Parallel Computing"}),"\n",(0,r.jsx)(e.p,{children:"Message Passing Interface (MPI) enables distributed parallel computing across multiple nodes."}),"\n",(0,r.jsx)(e.h3,{id:"mpi-container-strategy",children:"MPI Container Strategy"}),"\n",(0,r.jsx)(e.p,{children:"The key challenge with MPI containers is that the MPI version inside the container should be compatible with the host system's MPI. There are two approaches:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Hybrid approach"})," (recommended): Use host MPI to launch container processes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Container MPI"}),": Include MPI in the container (simpler but may have compatibility issues)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"exercise-3-mpi-container",children:"Exercise 3: MPI Container"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"mkdir -p ~/mpi-container\ncd ~/mpi-container\n"})}),"\n",(0,r.jsx)(e.p,{children:"Create an MPI test program:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > mpi_hello.py << \'EOF\'\n#!/usr/bin/env python3\n"""Simple MPI hello world with mpi4py."""\n\nfrom mpi4py import MPI\nimport socket\n\ndef main():\n    comm = MPI.COMM_WORLD\n    rank = comm.Get_rank()\n    size = comm.Get_size()\n    hostname = socket.gethostname()\n\n    print(f"Hello from rank {rank}/{size} on {hostname}")\n\n    # Simple collective operation\n    comm.Barrier()\n\n    if rank == 0:\n        print(f"\\n{\'=\'*50}")\n        print(f"MPI Info:")\n        print(f"  Total processes: {size}")\n        print(f"  MPI Version: {MPI.Get_version()}")\n        print(f"{\'=\'*50}")\n\nif __name__ == "__main__":\n    main()\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Create the Dockerfile:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > Dockerfile << \'EOF\'\nFROM ubuntu:22.04\n\nLABEL description="MPI-enabled Python container"\n\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install MPI and Python\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    python3 \\\n    python3-pip \\\n    openmpi-bin \\\n    libopenmpi-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install mpi4py\nRUN pip3 install --no-cache-dir mpi4py numpy\n\nWORKDIR /app\nCOPY mpi_hello.py .\n\n# Default to running the MPI program\nCMD ["python3", "mpi_hello.py"]\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Build:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"docker build -t mpi-hello:1.0 .\n"})}),"\n",(0,r.jsx)(e.h3,{id:"running-mpi-containers-on-ace-hpc",children:"Running MPI Containers on ACE HPC"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"#!/bin/bash\n#SBATCH --job-name=mpi-container\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=4\n#SBATCH --time=00:30:00\n\nmodule load apptainer\nmodule load openmpi\n\n# Run MPI across nodes using host MPI\nmpirun -np $SLURM_NTASKS apptainer exec mpi-hello.sif python3 /app/mpi_hello.py\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"optimization-techniques",children:"Optimization Techniques"}),"\n",(0,r.jsx)(e.h3,{id:"1-minimize-layers",children:"1. Minimize Layers"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# Bad: Many layers\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y git\nRUN apt-get clean\n\n# Good: Single layer\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends \\\n        curl \\\n        git \\\n    && apt-get clean \\\n    && rm -rf /var/lib/apt/lists/*\n"})}),"\n",(0,r.jsx)(e.h3,{id:"2-order-by-change-frequency",children:"2. Order by Change Frequency"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# Things that rarely change first\nFROM python:3.11-slim\n\n# System dependencies (rarely change)\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    libgomp1 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Python dependencies (change occasionally)\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Application code (changes frequently)\nCOPY src/ /app/src/\n"})}),"\n",(0,r.jsx)(e.h3,{id:"3-use-dockerignore",children:"3. Use .dockerignore"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# .dockerignore\n.git\n.gitignore\n__pycache__\n*.pyc\n.pytest_cache\n.venv\nvenv\n*.egg-info\ndist\nbuild\n.tox\n.coverage\nhtmlcov\n*.log\n.env\n.env.*\nDockerfile\ndocker-compose*.yml\n*.md\n!README.md\ndata/\noutput/\n"})}),"\n",(0,r.jsx)(e.h3,{id:"4-pin-versions-for-reproducibility",children:"4. Pin Versions for Reproducibility"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# requirements.txt with pinned versions\nFROM python:3.11.4-slim\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-txt",children:"# requirements.txt\nnumpy==1.24.3\npandas==2.0.3\nscikit-learn==1.3.0\nmatplotlib==3.7.2\n"})}),"\n",(0,r.jsx)(e.h3,{id:"5-use-specific-base-image-digests",children:"5. Use Specific Base Image Digests"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# Most reproducible: use digest\nFROM python:3.11.4-slim@sha256:abc123...\n\n# Good: specific version\nFROM python:3.11.4-slim\n\n# Avoid: tag can change\nFROM python:3.11-slim\nFROM python:latest\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"security-best-practices",children:"Security Best Practices"}),"\n",(0,r.jsx)(e.h3,{id:"1-run-as-non-root-user",children:"1. Run as Non-Root User"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'FROM python:3.11-slim\n\n# Create non-root user\nRUN useradd -m -s /bin/bash appuser\n\nWORKDIR /app\nCOPY --chown=appuser:appuser . .\n\n# Switch to non-root user\nUSER appuser\n\nCMD ["python", "app.py"]\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-never-include-secrets",children:"2. Never Include Secrets"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# NEVER do this\nENV API_KEY=secret123\nCOPY credentials.json /app/\n\n# Instead, mount at runtime:\n# docker run -v ~/.config/myapp:/config:ro myimage\n# apptainer exec --bind ~/.config/myapp:/config:ro container.sif\n"})}),"\n",(0,r.jsx)(e.h3,{id:"3-use-official-base-images",children:"3. Use Official Base Images"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# Good: Official images\nFROM python:3.11-slim\nFROM ubuntu:22.04\nFROM nvidia/cuda:12.2.0-runtime-ubuntu22.04\n\n# Avoid: Unknown sources\nFROM random-user/mystery-image:latest\n"})}),"\n",(0,r.jsx)(e.h3,{id:"4-verify-downloads",children:"4. Verify Downloads"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:'RUN curl -fsSL https://example.com/file.tar.gz -o file.tar.gz \\\n    && echo "abc123... file.tar.gz" | sha256sum -c - \\\n    && tar xzf file.tar.gz \\\n    && rm file.tar.gz\n'})}),"\n",(0,r.jsx)(e.h3,{id:"5-minimize-attack-surface",children:"5. Minimize Attack Surface"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-dockerfile",children:"# Remove unnecessary packages\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends needed-package \\\n    && apt-get purge -y --auto-remove \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Don't install documentation\nRUN pip install --no-cache-dir --no-compile package\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"exercise-4-optimized-ml-container",children:"Exercise 4: Optimized ML Container"}),"\n",(0,r.jsx)(e.p,{children:"Let's build a production-ready ML container using all techniques:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"mkdir -p ~/optimized-ml\ncd ~/optimized-ml\n"})}),"\n",(0,r.jsx)(e.p,{children:"Create requirements:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"cat > requirements.txt << 'EOF'\nnumpy==1.24.3\npandas==2.0.3\nscikit-learn==1.3.0\njoblib==1.3.2\nEOF\n"})}),"\n",(0,r.jsx)(e.p,{children:"Create the application:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > train_model.py << \'EOF\'\n#!/usr/bin/env python3\n"""Train a simple ML model."""\n\nimport argparse\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\'--output\', \'-o\', default=\'/output/model.joblib\')\n    parser.add_argument(\'--n-estimators\', type=int, default=100)\n    args = parser.parse_args()\n\n    print("Loading data...")\n    iris = load_iris()\n    X_train, X_test, y_train, y_test = train_test_split(\n        iris.data, iris.target, test_size=0.2, random_state=42\n    )\n\n    print(f"Training RandomForest with {args.n_estimators} estimators...")\n    model = RandomForestClassifier(n_estimators=args.n_estimators, random_state=42)\n    model.fit(X_train, y_train)\n\n    # Evaluate\n    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n    print(f"Cross-validation accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")\n\n    y_pred = model.predict(X_test)\n    print("\\nTest set classification report:")\n    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n\n    # Save model\n    joblib.dump(model, args.output)\n    print(f"\\nModel saved to {args.output}")\n\nif __name__ == "__main__":\n    main()\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Create the optimized Dockerfile:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'cat > Dockerfile << \'EOF\'\n# Stage 1: Builder\nFROM python:3.11-slim AS builder\n\nWORKDIR /build\n\n# Install build dependencies\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends \\\n        build-essential \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create venv and install packages\nRUN python -m venv /opt/venv\nENV PATH="/opt/venv/bin:$PATH"\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n\n# Stage 2: Runtime\nFROM python:3.11-slim\n\n# Metadata\nLABEL maintainer="your.email@example.com"\nLABEL description="Optimized ML training container"\nLABEL version="1.0"\n\n# Install only runtime dependencies\nRUN apt-get update \\\n    && apt-get install -y --no-install-recommends \\\n        libgomp1 \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && useradd -m -s /bin/bash mluser\n\n# Copy virtual environment\nCOPY --from=builder /opt/venv /opt/venv\nENV PATH="/opt/venv/bin:$PATH"\n\n# Set up application\nWORKDIR /app\nCOPY --chown=mluser:mluser train_model.py .\n\n# Create output directory\nRUN mkdir -p /output && chown mluser:mluser /output\n\n# Switch to non-root user\nUSER mluser\n\nENTRYPOINT ["python", "train_model.py"]\nCMD ["--help"]\nEOF\n'})}),"\n",(0,r.jsx)(e.p,{children:"Build and test:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Build\ndocker build -t ml-train:1.0 .\n\n# Check size\ndocker images ml-train:1.0\n\n# Test\nmkdir -p output\ndocker run -v $(pwd)/output:/output ml-train:1.0 --output /output/model.joblib\n\n# Verify model was saved\nls -la output/\n"})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"container-size-comparison",children:"Container Size Comparison"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Approach"}),(0,r.jsx)(e.th,{children:"Typical Size"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsxs)(e.td,{children:[(0,r.jsx)(e.code,{children:"python:3.11"})," + packages"]}),(0,r.jsx)(e.td,{children:"1.5-2 GB"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsxs)(e.td,{children:[(0,r.jsx)(e.code,{children:"python:3.11-slim"})," + packages"]}),(0,r.jsx)(e.td,{children:"400-600 MB"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Multi-stage with slim"}),(0,r.jsx)(e.td,{children:"150-300 MB"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Multi-stage + optimization"}),(0,r.jsx)(e.td,{children:"100-200 MB"})]})]})]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"In this tutorial, you learned:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Multi-stage builds"}),": Separate build and runtime for smaller images"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GPU containers"}),": Use NVIDIA CUDA base images and cuDNN"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"MPI containers"}),": Enable parallel computing across nodes"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Optimization"}),": Layer ordering, caching, and cleanup techniques"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Security"}),": Non-root users, no secrets, verified downloads"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(e.p,{children:["Continue to ",(0,r.jsx)(e.strong,{children:(0,r.jsx)(e.a,{href:"containers-hpc",children:"Containers on HPC Clusters"})})," to learn how to:"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Run containers on ACE HPC with Apptainer"}),"\n",(0,r.jsx)(e.li,{children:"Write SLURM job scripts for containerized workloads"}),"\n",(0,r.jsx)(e.li,{children:"Manage data with bind mounts"}),"\n",(0,r.jsx)(e.li,{children:"Optimize performance on the cluster"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://docs.docker.com/build/building/multi-stage/",children:"Docker Multi-stage Builds"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://catalog.ngc.nvidia.com/",children:"NVIDIA NGC Catalog"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://mpi4py.readthedocs.io/",children:"mpi4py Documentation"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://apptainer.org/docs/user/latest/gpu.html",children:"Apptainer GPU Support"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>l});var t=i(6540);const r={},a=t.createContext(r);function s(n){const e=t.useContext(a);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:s(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);